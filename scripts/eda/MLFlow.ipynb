{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza la carga de las librerías requeridas en el proceso."
      ],
      "metadata": {
        "id": "P-dVFfCP4snS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from numbers import Number\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import json\n",
        "import random\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "import mlflow.keras"
      ],
      "metadata": {
        "id": "dyzehiYpXeb7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión MlFlow\n",
        "\n",
        "En esta sección se genera la conexión a MlFlow mediante *ngrok* con el fin de poder tener acceso a la interfaz gráfica de la herramienta."
      ],
      "metadata": {
        "id": "Dmm2I0W5a9sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow requests\n",
        "import mlflow\n",
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6SQ6dy0bFTU",
        "outputId": "cab0b588-c3bb-4e69-c2ec-ad095a695d7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.13.0-py3-none-any.whl (25.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Collecting opentelemetry-api<3,>=1.0.0 (from mlflow)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk<3,>=1.0.0 (from mlflow)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.0)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<23 (from mlflow)\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.0.0->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk<3,>=1.0.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.14.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, querystring-parser, opentelemetry-semantic-conventions, Mako, importlib-metadata, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, alembic, opentelemetry-sdk, graphene, gitpython, mlflow\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 aniso8601-9.0.1 deprecated-1.2.14 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 importlib-metadata-7.0.0 mlflow-2.13.0 opentelemetry-api-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"\"\"\n",
        "mlflow server \\\n",
        "        --backend-store-uri sqlite:///tracking.db \\\n",
        "        --default-artifact-root file:mlruns \\\n",
        "        -p 5000 &\n",
        "\"\"\"\n",
        "get_ipython().system_raw(command)"
      ],
      "metadata": {
        "id": "hwh1hCF8bIto"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hn-EjY1bMTJ",
        "outputId": "11887ed9-ee6f-4361-a453-526bc0e77ab7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = \"2g3elaQlzc0qSVIqOJWR4rApSoT_2TSiaCTXVnsD2LzY2LLYk\" # Agregue el token dentro de las comillas\n",
        "os.environ[\"NGROK_TOKEN\"] = token"
      ],
      "metadata": {
        "id": "sPVGqat0bOEV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken $NGROK_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a-iIn9abQEv",
        "outputId": "fed834c6-2797-4279-b03f-0d5657d96187"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.connect(5000, \"http\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoYPMHAgbRh6",
        "outputId": "0048d4c9-aeff-4af2-a530-0130d246c0c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://f03a-34-125-253-33.ngrok-free.app\" -> \"http://localhost:5000\">"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri(\"http://localhost:5000\")"
      ],
      "metadata": {
        "id": "UyfdIzEPbT32"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp_id = mlflow.create_experiment(name=\"proyecto_mdls6_v1\", artifact_location=\"mlruns/\")"
      ],
      "metadata": {
        "id": "8ZF5Pa4LbVmu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publicación Model_128N"
      ],
      "metadata": {
        "id": "I4ij3Zr4uaPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UKT29Ky8VJIs"
      },
      "outputs": [],
      "source": [
        "#Definimos el modelo en keras\n",
        "conv_net = tf.keras.models.Sequential()\n",
        "\n",
        "#Capa de entrada\n",
        "width  =X_train.shape[1]\n",
        "height  =X_train.shape[2]\n",
        "conv_net.add(tf.keras.layers.Input(shape=(width, height, 3)))\n",
        "\n",
        "#Primer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 8, kernel_size = 5, activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Segundo bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 16,\n",
        "    kernel_size = 4,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Tercer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 32,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Cuarto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 64,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Quinto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 128,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Sexto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 256,\n",
        "    kernel_size = 2,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#capa flatten, que transforma cualquier arreglo multidimensional en un vector unidimensional.\n",
        "conv_net.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#####Clasificador\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Agregamos dropout para regularización\n",
        "conv_net.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Capa de salida\n",
        "conv_net.add(tf.keras.layers.Dense(units=18, #Número de categorías\n",
        "                                   activation='softmax')) #Clasificación multiclase\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net.load_weights(\"best_weights_128N.h5\")\n",
        "\n",
        "y_pred = conv_net.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)  # Obtener la clase con la mayor probabilidad\n",
        "\n",
        "# Obtener las etiquetas reales\n",
        "y_true = Y_test_1.argmax(axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc8z5EzuZMmO",
        "outputId": "b566d0f7-5c9e-489c-8eac-a28ed558c32a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 5s 475ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(classification_report(y_true, y_pred_classes, output_dict=True)).transpose()\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "loss = log_loss(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LhVeKxja2yz",
        "outputId": "d4b89e67-c81d-42a6-99f7-264d39503d5f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = mlflow.start_run(\n",
        "        run_name=\"model_128N\", experiment_id=exp_id\n",
        "        )\n",
        "\n",
        "model=conv_net\n",
        "\n",
        "precision= report_df.loc[\"macro avg\"][0]\n",
        "recall= report_df.loc[\"macro avg\"][1]\n",
        "f1_score= report_df.loc[\"macro avg\"][2]\n",
        "\n",
        "mlflow.keras.log_model(model, \"model\")\n",
        "\n",
        "mlflow.log_metrics({\n",
        "        \"accuracy\":accuracy,\n",
        "        \"loss\":loss,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "        })\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "IpRizz_jc2F9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8246ac5a-a3a2-4aec-f881-ba5cf5eeda5c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/23 00:09:16 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publicación Model_256N"
      ],
      "metadata": {
        "id": "LunCeH1-vQaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el modelo en keras\n",
        "conv_net = tf.keras.models.Sequential()\n",
        "\n",
        "#Capa de entrada\n",
        "width  =X_train.shape[1]\n",
        "height  =X_train.shape[2]\n",
        "conv_net.add(tf.keras.layers.Input(shape=(width, height, 3)))\n",
        "\n",
        "#Primer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 8, kernel_size = 5, activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Segundo bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 16,\n",
        "    kernel_size = 4,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Tercer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 32,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Cuarto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 64,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Quinto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 128,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#capa flatten, que transforma cualquier arreglo multidimensional en un vector unidimensional.\n",
        "conv_net.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#####Clasificador\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "\n",
        "# Agregamos dropout para regularización\n",
        "conv_net.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Capa de salida\n",
        "conv_net.add(tf.keras.layers.Dense(units=18, #Número de categorías\n",
        "                                   activation='softmax')) #Clasificación multiclase"
      ],
      "metadata": {
        "id": "LFfUKYpyvRqm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net.load_weights(\"best_weights_256N.h5\")\n",
        "\n",
        "y_pred = conv_net.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)  # Obtener la clase con la mayor probabilidad\n",
        "\n",
        "# Obtener las etiquetas reales\n",
        "y_true = Y_test_1.argmax(axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_UOy7DovZSG",
        "outputId": "291dc903-fb4e-4afd-d51d-d56fd5a0b0c0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 411ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(classification_report(y_true, y_pred_classes, output_dict=True)).transpose()\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "loss = log_loss(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mBhCaQDveGt",
        "outputId": "0a532ade-4d14-4921-ec8c-e30cbb593b00"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = mlflow.start_run(\n",
        "        run_name=\"model_256N\", experiment_id=exp_id\n",
        "        )\n",
        "\n",
        "model=conv_net\n",
        "\n",
        "precision= report_df.loc[\"macro avg\"][0]\n",
        "recall= report_df.loc[\"macro avg\"][1]\n",
        "f1_score= report_df.loc[\"macro avg\"][2]\n",
        "\n",
        "mlflow.keras.log_model(model, \"model\")\n",
        "\n",
        "mlflow.log_metrics({\n",
        "        \"accuracy\":accuracy,\n",
        "        \"loss\":loss,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "        })\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkuU6Uj0vgYu",
        "outputId": "15e13980-3c89-4acb-b336-21c567411f9d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/23 00:10:25 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publicación Model_512N"
      ],
      "metadata": {
        "id": "ptJLNXqDv4MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el modelo en keras\n",
        "conv_net = tf.keras.models.Sequential()\n",
        "\n",
        "#Capa de entrada\n",
        "width  =X_train.shape[1]\n",
        "height  =X_train.shape[2]\n",
        "conv_net.add(tf.keras.layers.Input(shape=(width, height, 3)))\n",
        "\n",
        "#Primer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 8, kernel_size = 6, activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Segundo bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 16,\n",
        "    kernel_size = 5,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Tercer bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 32,\n",
        "    kernel_size = 4,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Cuarto bloque\n",
        "conv_net.add(tf.keras.layers.Conv2D(\n",
        "    filters = 64,\n",
        "    kernel_size = 3,\n",
        "    activation = 'relu'\n",
        "))\n",
        "conv_net.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "#capa flatten, que transforma cualquier arreglo multidimensional en un vector unidimensional.\n",
        "conv_net.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#####Clasificador\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "\n",
        "# Capa densa intermedia\n",
        "conv_net.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "\n",
        "# Agregamos dropout para regularización\n",
        "conv_net.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Capa de salida\n",
        "conv_net.add(tf.keras.layers.Dense(units=18, #Número de categorías\n",
        "                                   activation='softmax')) #Clasificación multiclase\n"
      ],
      "metadata": {
        "id": "zOqPw_zIv5l8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net.load_weights(\"best_weights_512N.h5\")\n",
        "\n",
        "y_pred = conv_net.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)  # Obtener la clase con la mayor probabilidad\n",
        "\n",
        "# Obtener las etiquetas reales\n",
        "y_true = Y_test_1.argmax(axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOqOE_uEv9_z",
        "outputId": "6ccdd143-b5f9-4349-e9b7-9c3cd42daf86"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 5s 468ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(classification_report(y_true, y_pred_classes, output_dict=True)).transpose()\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "loss = log_loss(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSbs2OJIwBxV",
        "outputId": "70857585-da71-4aae-b7b8-6c6d27156562"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = mlflow.start_run(\n",
        "        run_name=\"model_512N\", experiment_id=exp_id\n",
        "        )\n",
        "\n",
        "model=conv_net\n",
        "\n",
        "precision= report_df.loc[\"macro avg\"][0]\n",
        "recall= report_df.loc[\"macro avg\"][1]\n",
        "f1_score= report_df.loc[\"macro avg\"][2]\n",
        "\n",
        "mlflow.keras.log_model(model, \"model\")\n",
        "\n",
        "mlflow.log_metrics({\n",
        "        \"accuracy\":accuracy,\n",
        "        \"loss\":loss,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score\n",
        "        })\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdPWX4w_wHKA",
        "outputId": "499cf4b0-56a1-4f24-b55f-cada0fc35df1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/23 00:10:52 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    }
  ]
}